{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ca0c03-6247-48d8-a1d6-7ee0045f6db8",
   "metadata": {},
   "source": [
    "## Basics of Neutral Networks\n",
    "### What are they?\n",
    "\n",
    "Neutral network (NN) is a function detecting some patterns (rules) in input data. In other words, it eliminates the need for a priori programming, enanbling selected process to become fully automated.\n",
    "\n",
    "NN find their use in popular groups of tasks like:\n",
    "- classification - assigning into defined target categories,\n",
    "- detection - determining the position of the classified objects,\n",
    "- segmentation - diving into groups with similar characteristics,\n",
    "\n",
    "in many fields e.g. biomedical engineering, automotive industry (autonomous behaviors) or linguistics. \n",
    "\n",
    "Deep learning can be understood as class of multilayer structures (NNs), consisting of 3 main parts: input layer (data), hidden layers (magic box responsible for proceesing) and output layer (results). These layers are in charge of performing different transformations and operations, like adaptive filtration, selection, regularization and normalization, that will be introducted in next paragraphs.\n",
    "  \n",
    "image\n",
    "\n",
    "###  How do they learn? \n",
    "\n",
    "First of all, there are two main way of NN learning: supervised that takes as input data with correspodning labels, and unsupervised, that on the contrary bases only on data to detect some common characteristic, aiming to cluster objects. Let's firstly dive into supervised method.\n",
    "\n",
    "In this case, learning is treated as gaining ability to map correctly inputs to outputs, so it's a process of establishing rules.  \n",
    "\n",
    "What does it mean indeed - \"learning of mapping inputs to output\"?\n",
    "\n",
    "Before we start, it's crucial to remain that in computer's world it's all about numbers. Single word can be encoded as number, image can be understood as matrix of numbers. For example, RGB image refers to 3D matrix that defines red, green and blue components for each individual pixel. In case of grayscale image, matrix limits only to one component.   \n",
    "\n",
    "image\n",
    "\n",
    "`McCullocha-Pitts neuron` - one of the mathematical neuron's model. It's consist of many inputs, each of which is assigned a real number (`weight`), and one output. Moreover, added value is called as `bias` and used for offset the result. From mathematical point of view, single neuron is a function - linear transformation. It takes inputs, calculates them by weights, adds bias, computes the value of `activation function` of the determined sum, and as the result, spits out a number between 0 and 1. In this process, activation function plays a crucial role to ensure well model generalization and accurate prediction. It introduces nonlinearity to models, which allows deep learning models to learn highly complex patterns. There are many types of them: binary step function, linear and non-linear functions (tahn, sigmoid or ReLU). In case of binary classification, sigmoid method should be chosen as the activation function of output layer, but for multi-class classification softmax function. \n",
    "\n",
    "The McCulloch–Pitts neuron is the basic building block of a `Perceptron NN` (a simple supervised binary classifier). In turn, many perceptrons placed in one layer creates a \"Fully Connected (Dense) Layer\", in which all neurons of successive layers are connected to each other.\n",
    "\n",
    "Okey, so that's the NN archicture, but still - how does this learning look like?\n",
    "\n",
    "NN learning is an iterative process. Each iteration means doing some calculations by network, its performance evaluation and weights modification based on the result. In a nutshell, a NN learning is a process of finding the right parameters: weights and biases. \n",
    "\n",
    "But...how this NN knows, how to modify these weights to get better results?\n",
    "\n",
    "It is done by `loss function`, telling the model wheather it perfoms correctly or not. The cost of a single training example is calculated by quantifying the difference between predicted and actual outputs. `Cost function` is understood as the average of all loss function values. There are many popular functions depending on the problem: regression (MSE, MAE, Huber) and classification (binary cross-entropy, categorial cross-entropy etc). The goal is to minimalize the cost function, by changing weights of each hidden layers. It is done by calculating `gradient decent`, and `back propagation algorithm` is the most efficient method for computing it.\n",
    "\n",
    "`Gradient decent algorithm` helps to figure out what is the downhill direction. This direction is the negative of the gradient of the cost function, and its magnitude is a indicator of the slope's steepness = rate of change.  Moreover, the magnitude of each component of calculated gradient vector tells how sensitive the cost function is to each weight and bias. The training process consists of calculating gradient, taking a small step downhill (weights modification) and just repeating that over and over till finding minimum of the cost function (local or global). In this process, there are three main meaningful hyperparameters: `learning rate` meaning the amount of apportioned error that the weights of the model are updated, `momentum` helping to prevent oscillations, indicating how many gradients from the past are considered (higher = more), and `decay` adjusting learning rate (lr) per iterations. Setting proper values of these parameters makes it easier to converge towards some local minimum of a cost function. Unfortunatelly,  our loss function usually has various local minima, which can missguide the model. In order to prevent it, we can manually monitor and fix learning rate parameter - but it is impossible. That is why we should set the `optimizer` parameter that does this for us. It optimizes the learning rate automatically to avoid entering a local minimum and is also responsible for fastening the optimization process. The most popular optimizers are Adam, RMS prop, Adagrad. \n",
    "\n",
    "\n",
    "What is the best way to verify if model trained correctly?\n",
    "After training model, there is a evaluation phrase. You show it more labeled data (testing data), that it has never seen before. Then you can see how accurately the model classifies those images.\n",
    "\n",
    "The main clue is to correctly preprocess data and choose network architecture and its parameters = determine model complexity. It depends only on you, how many layers the network will have, what type of activation functions, loss functions, optimizers...and so on. \n",
    "\n",
    "###  Loss functions\n",
    "\n",
    "Różnice między funkcjami strat (loss functions) wynikają z różnych celów, które realizują w różnych zadaniach oraz odmiennych właściwości matematycznych, które mają wpływ na sposób trenowania modelu. Oto zestawienie najpopularniejszych funkcji strat:\n",
    "- KLASYFIKACJA \n",
    "    -  Binary Cross Entropy\n",
    "        - prosty i efektowny dla zadań z klasyfikacją binarną\n",
    "        - umożliwia obliczenie prawdopdoibieństwa przynależności do danej klasy\n",
    "        - wrażliwy na zbiory niezbalansowane\n",
    "    -  Categorical Cross Entropy\n",
    "        - dla klasyfikacji wieloklasowej\n",
    "- SEGMENTACJA\n",
    "    - Dice Loss\n",
    "        - Dobry dla problemów z niezbalansowanymi klasami\n",
    "        - Miara podobieństwa - ocenia jak dobrze przewidywana maska pokrywa się z klasą wyrażona jako stosunek: 1 - 2x area of intersection / total area \n",
    "    - Intersection over Union (IoU)\n",
    "        - wyrażone jako stosunek: area of intersection / area of union\n",
    "- REGRESJA\n",
    "    -  MSE - Mean Squared Error\n",
    "        - łatwy w obliczeniach jako suma kwadratów odległości euklidesowych między wartościami\n",
    "        - wrażliwy na wartości odstające (outliers)\n",
    "    - MAE - Mean Absolute Error\n",
    "        - odporny na wartości odstające\n",
    "        - gradienty nie są tak gładkie więc proces uczenia może być bardziej chaotyczny\n",
    "\n",
    "###  Metrics\n",
    "\n",
    "There are several metrics helping in performance model assesment. Depending on task type, you should conclude based on proper indicator(s).\n",
    "- KLASYFIKACJA\n",
    "    - Accuracy - dokładność\n",
    "        - stosunek poprawnie sklasyfikowanych próbek do wszystkich próbek w zbiorze danych. \n",
    "        - Myląca w przypadku niezrównoważonych klas, ponieważ wysoka dokładność może wynikać z dominacji jednej klasy (np. w problemach, gdzie jedna klasa jest bardzo często reprezentowana).\n",
    "    - Recall - czułość, wrażliwość\n",
    "        - mierzy zdolność modelu do wykrywania pozytywnych przypadków (klasa pozytywna).\n",
    "        - dobrze nadaje się do zadań, gdzie wykrycie pozytywnej klasy jest kluczowe (np. w wykrywaniu chorób, spamie).\n",
    "        - może prowadzić do false positive - fałszywych alarmów\n",
    "    - Precision - precyzja\n",
    "        - Miara tego, jak dokładne są pozytywne przewidywania modelu (tj. ile z przewidywanych pozytywnych przykładów jest faktycznie pozytywnych).\n",
    "    - F1 score\n",
    "        - średnia harmoniczna między precyzją i recall, co pozwala uzyskać bardziej wyważoną ocenę, gdy klasyfikator ma problemy z równowagą między tymi dwoma metrykami.\n",
    "        - miara wydajności, która jest szczególnie użyteczna w przypadkach, gdy klasyfikator ma nierównomierny rozkład klas (np. w sytuacji, gdy mamy do czynienia z problemem niezrównoważonych klas).\n",
    "        - Może maskować słabe wyniki: Jeśli model ma bardzo niską wartość recall lub precyzji, F1-score może nadal dawać wartość pośrednią, co może ukrywać problemy z modelem.\n",
    "    - ROC Curve (Receiver Operating Characteristic Curve)\n",
    "        - Krzywa ROC to wykres przedstawiający stosunek True Positive Rate (TPR) do False Positive Rate (FPR) dla różnych progów decyzyjnych.\n",
    "    - Confusion Matrix  - macierz pomyłek\n",
    "        - tabela, która przedstawia wyniki predykcji modelu, rozdzielając je na cztery kategorie w przypadku klasyfikacji binarnej:\n",
    "- SEGMENTACJA\n",
    "    - Dice Coefficient\n",
    "        - miara podobieństwa między dwiema zbiorami (np. przewidywaną maską a rzeczywistą maską), szczególnie przydatna w segmentacji obrazów.\n",
    "        - wyrażona jako stosunek: 2 * area of intersection / total area\n",
    "        - Może być wrażliwa na bardzo małe obszary (np. małe obiekty w obrazie).\n",
    "    - Intersection over Union (IoU)\n",
    "        - IoU mierzy zgodność między przewidywaną a rzeczywistą maską, odnosząc pole wspólne (intersection) do pola łącznego (union) obu masek.\n",
    "        - Wyrażona jako stosunek: area of intersection / area of union\n",
    "    - Hausdorff Coefficient (Hausdorff Distance)\n",
    "        - mierzy najdalszą odległość pomiędzy dwoma zbiorami punktów, co może być pomocne przy analizie jakości segmentacji w kontekście topologicznym.\n",
    "        - to maksimum z minimalnych odległości między dwoma krzywymi (liczona podwójna A z B i B do A)\n",
    "\n",
    "\n",
    "### Common issues\n",
    "\n",
    "- Unrepresentative data - Niereprezentatywne dane to dane, które nie odzwierciedlają dobrze rzeczywistego rozkładu i zmienności w prawdziwym świecie.\n",
    "- Imbalanced data\n",
    "In ideal scenario the data are balanced. Unfortunatelly, there is usually a problem with it. You want to get as balanced data as it is possible, but luckily there are a lot of popular techniques to hadle imbalanced data like resampling, loss functions with weights, cross-validation or using right evaluation metrics.\n",
    "    - Solutions:\n",
    "        - Resampling: undersampling or upsampling\n",
    "        - Loss functions with weights\n",
    "        - Dataloader with weights - changed probability for each class\n",
    "        - cross validation - to proof that  training and testing sets are representative\n",
    "- Overfitting - model \"uczy się\" zbyt dokładnie na danych treningowych, w tym także z błędów i szumów. Skutkuje to słabą generalizacją modelu na dane testowe lub nowe dane, ponieważ model stał się zbyt dopasowany do specyfiki danych treningowych, a nie rzeczywistego rozkładu danych.\n",
    "    - Solutions:\n",
    "        - Regularizations - działa poprzez dodanie kary do funkcji straty, która penalizuje zbyt dużą złożoność modelu \n",
    "            - L1 (Lasso) - dodaje do funkcji straty sumę wartości bezwzględnych wag modelu, czyli L1 norm. Ta technika ma tendencję do \"wymuszania\" wielu wag w modelu na zero, co prowadzi do oszczędności cech (feature selection). Dzięki temu model staje się prostszy, z mniejszą liczbą cech, które mają wpływ na przewidywania. A zostają tylko te cechy, które naprawdę wpływają na wynik\n",
    "            - L2 (Ridge) - dodaje do funkcji straty sumę kwadratów wag modelu, czyli L2 norm. W przeciwieństwie do L1, L2 nie zmusza wag do bycia zerowymi, ale zmniejsza ich wartość, dzięki czemu model staje się mniej wrażliwy na dane treningowe i bardziej ogólny. Lepszy gdy mamy róźne cechy, mniej i bardziej istotne ale chcemy użyć je wszystkie. Stabilizuje model, ponieważ unika sytuacji, gdzie pojedyncze cechy mają zbyt dużą wagę\n",
    "            - L1 + L2 Regularization (Elastic Net)\n",
    "                - połączenie L1 i L2 regularizacji, które łączy zalety obu metod. Jest używane w przypadku, gdy mamy wiele cech i nie jesteśmy pewni, która regularizacja będzie najlepsza. Elastic Net jest stosowane, gdy chcemy mieć selektora cech (L1) oraz redukcję wag (L2), aby zapewnić lepszą generalizację modelu.\n",
    "        - warstwa Dropout - polegająca na losowym wyłączaniu pewnego procentu neuronów podczas treningu. Z każdym krokiem treningowym model \"losowo\" decyduje, które neurony będą aktywne, a które będą wyłączone. To zmusza model do nauki bardziej ogólnych reprezentacji, które nie są zależne od pojedynczych neuronów.       \n",
    "        - Cross-validation\n",
    "        - Early stopping\n",
    "        - Data augmentation\n",
    "        - Reduce complexity of the model\n",
    "- Underfitting - model jest zbyt prosty, aby uchwycić złożoność danych, przez co nie potrafi poprawnie uchwycić wzorców w zbiorze treningowym. W efekcie model ma niską dokładność zarówno na danych treningowych, jak i testowych.\n",
    "    - Solutions:\n",
    "        - Increase model complexity\n",
    "        - Feature engineering - create new features that can more accurate represent data\n",
    "        - Adjusting hyperparameters via eg. GridSearch\n",
    "\n",
    "## Practical part explanation\n",
    "\n",
    "- `Batch size parameter` represents the number of samples used in one forward and backward pass through the network.\n",
    "- `Number of epochs parameter` determines how many times the model will see the entire training data before completing training.\n",
    "\n",
    "Created by Agnieszka Florkowska, 2024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37964d25-51af-42aa-89dd-8553bd1b0319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
