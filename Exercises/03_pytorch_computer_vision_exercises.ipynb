{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vex99np2wFVt"
   },
   "source": [
    "# 03. PyTorch Computer Vision Exercises\n",
    "\n",
    "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
    "\n",
    "They're a bunch of fun.\n",
    "\n",
    "You're going to get to write plenty of code!\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/). \n",
    "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA). \n",
    "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
    "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaeYzOTLwWh2",
    "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 25 15:07:12 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8             12W /   55W |       0MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     25596      C   ...anaconda3\\envs\\torch_gpu\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "9c150c50-a092-4f34-9d33-b45247fb080d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# TODO: Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSFX7tc1w-en"
   },
   "source": [
    "## 1. What are 3 areas in industry where computer vision is currently being used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyWRkvWGbCXj"
   },
   "source": [
    "Currently, computer vision is used in many areas in industry, eg: \n",
    "- medicine: navigation of medical tools;\n",
    "- automotive: support for drivers: recognition of others cars, pedestrians etc;\n",
    "- fitness and sports: self-tracking system helping to exercise correctly\n",
    "- education, ecommerce, agriculture etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBK-WI6YxDYa"
   },
   "source": [
    "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1rxD6GObCqh"
   },
   "source": [
    "Overfitting is a phenomenon in machine learning, when the model is too fitted to training data, and it loses the ability to generalize (= achieving satisfying results on testing data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeYFEqw8xK26"
   },
   "source": [
    "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each. \n",
    "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocvOdWKcbEKr"
   },
   "source": [
    "There are many possible ways of preventing overfitting in machine learning. The most common are:\n",
    "- use more training data - when a model is trained on a larger dataset, it can learn a broader range of patterns, making it less likely to memorize the noise or specific quirks of a smaller dataset\n",
    "- use regularizations - regularization techniques add a penalty to the loss function used to train the model, discouraging overly complex models that may overfit the training data. The most common regularizations are: L1, L2 and Dropout layern. \n",
    "- use less complex model (= simplify it) - simplifying the model involves reducing the number of parameters or features. This can be achieved by: reducing the number of features (like hidden neurons) or chosing a simpler model architecture. Simpler models are less likely to capture noise and overfit, as they have a lower capacity to model complex patterns in the data.\n",
    "- use data augmentation - data augmentation involves artificially increasing the size of the training dataset by creating modified versions of existing data points. This is especially common in image processing, where techniques such as rotation, scaling, flipping, and cropping are used to create new training samples. \n",
    "- use early stopping - it pauses the training phase before the machine learning model learns the noise in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKdEEFEqxM-8"
   },
   "source": [
    "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
    "\n",
    "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqZaJIRMbFtS"
   },
   "source": [
    "Here are a few reasons why the later layers in a CNN see more of the image than the earlier layers:\n",
    "- Hierarchical feature learning: CNNs are designed to learn hierarchical representations of features in an image. The early layers of a CNN learn low-level features such as edges and textures, while the deeper layers learn high-level features such as shapes and objects. By gradually increasing the receptive field of the neurons in the network, the later layers can capture more global information and context about the image, which is essential for making accurate predictions.\n",
    "- Spatial hierarchy: In an image, local features (such as edges and corners) are combined to form more complex patterns and objects at higher levels of abstraction. By increasing the receptive field of the neurons in the later layers, the network can capture these spatial hierarchies and relationships between different parts of the image, leading to better representation learning.\n",
    "- Downsampling: Pooling layers are often used in CNNs to downsample the feature maps and reduce the spatial dimensions while retaining important features. As the network progresses through the layers, the spatial dimensions of the feature maps decrease due to the pooling operations, allowing the later layers to have a broader view of the input image.\n",
    "- Translation invariance: By allowing the later layers to have a larger receptive field, the network can achieve translation invariance, which means that the network's predictions are not sensitive to small translations in the input image. This property is crucial for tasks such as object recognition, where the position of an object in the image should not affect the network's ability to recognize it.\n",
    "\n",
    "In summary, the design of CNNs with increasing receptive fields in the later layers helps the network learn hierarchical representations of features, capture spatial hierarchies in the input image, downsample the feature maps for efficiency, and achieve translation invariance, all of which contribute to the network's ability to effectively learn and recognize patterns in images.\n",
    "\n",
    "Source: https://www.quora.com/In-a-CNN-why-do-the-later-layers-see-more-of-the-image-than-the-earlier-layers-Shouldnt-it-be-the-other-way-around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvf-3pODxXYI"
   },
   "source": [
    "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SHjeuN81bHza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:04<00:00, 2338311.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 143466.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:03<00:00, 445715.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4456264.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\", # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # images come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False, # get test data\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000 10000 10000\n",
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets))\n",
    "\n",
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxZW-uAbxe_F"
   },
   "source": [
    "## 6. Visualize at least 5 different samples of the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QVFsYi1PbItE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 1, 5\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPDzW0wxhi3"
   },
   "source": [
    "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALA6MPcFbJXQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCCVfXk5xjYS"
   },
   "source": [
    "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5IKNF22XbKYS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sf_3zUr7xlhy"
   },
   "source": [
    "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSo6vVWFbNLD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1CsHhPpxp1w"
   },
   "source": [
    "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YGgZvSobNxu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQwzqlBWxrpG"
   },
   "source": [
    "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSrXiT_AbQ6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lj6bDhoWxt2y"
   },
   "source": [
    "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leCTsqtSbR5P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHS20cNTxwSi"
   },
   "source": [
    "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset. \n",
    "* Then plot some predictions where the model was wrong alongside what the label of the image should've been. \n",
    "* After visualing these predictions do you think it's more of a modelling error or a data error? \n",
    "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78a8LjtdbSZj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUsDcN/+FAm9Pf7Ifqs6AZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "03_pytorch_computer_vision_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
